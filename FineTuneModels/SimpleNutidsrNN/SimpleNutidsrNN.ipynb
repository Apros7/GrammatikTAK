{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df...\n",
      "Done loading df...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"EuroparlNutidsr_trainset_verbs.csv\"\n",
    "print(\"Loading df...\")\n",
    "df = pd.read_csv(filename, encoding=\"UTF-8\", sep=\";\")\n",
    "print(\"Done loading df...\")\n",
    "pos = list(df[\"comment_text\"].values)\n",
    "labels = list(df[\"label\"].values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pos, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "unique_pos = ['NOUN','PUNCT','VERB','PRON','NUM','ADP','X','<PAD>','CCONJ','PROPN','AUX','SCONJ','INTJ','ADV','ADJ','PART','SYM','DET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NutidsrTokenizer():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        print(\"Initializing tokenizer...\")\n",
    "        self.tokenize_table = {x: i for i, x in enumerate(unique_pos)}\n",
    "        print(\"Tokenizer initialized.\")\n",
    "\n",
    "    def __call__(self, pos_list):\n",
    "        for pos_string in tqdm(pos_list):\n",
    "            splitted_pos = pos_string.split()\n",
    "            numbers = [self.tokenize_table[x] for x in splitted_pos]\n",
    "            yield [y for x in numbers for y in self._one_hot_encode(x)]\n",
    "    \n",
    "    def _one_hot_encode(self, number):\n",
    "        return [1 if i == number else 0 for i in range(18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NutidsrModel():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        number_of_unique_pos = 18\n",
    "        number_of_pos_including_padding = 21\n",
    "        self.l1 = Tensor.scaled_uniform(number_of_pos_including_padding*number_of_unique_pos, 256)\n",
    "        self.l2 = Tensor.scaled_uniform(256, 256)\n",
    "        self.l3 = Tensor.scaled_uniform(256, 64)\n",
    "        self.l4 = Tensor.scaled_uniform(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.dot(self.l1).leakyrelu(0.2)\n",
    "        x = x.dot(self.l2).leakyrelu(0.2)\n",
    "        x = x.dot(self.l3).leakyrelu(0.2)\n",
    "        x = x.dot(self.l4).sigmoid()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "Tokenizer initialized.\n",
      "Tokenizing train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1716972/1716972 [01:06<00:00, 25977.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190775/190775 [00:10<00:00, 18386.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Tokenizing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = NutidsrTokenizer()\n",
    "print(\"Tokenizing train...\")\n",
    "x_train_tokenized = list(tokenizer(X_train))\n",
    "print(\"Tokenizing test...\")\n",
    "x_test_tokenized = list(tokenizer(X_test))\n",
    "print(\"Done Tokenizing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "INFO: Epochs:  10 . Batch size:  128 . Steps pr. epoch:  13413 . Eval steps:  1490\n"
     ]
    }
   ],
   "source": [
    "EPOCHS, BATCH_SIZE = 10, 128\n",
    "\n",
    "model = NutidsrModel()\n",
    "optimizer = optim.Adam(optim.get_parameters(model),lr=0.0002, b1=0.5)\n",
    "\n",
    "n_steps = len(x_train_tokenized) // BATCH_SIZE\n",
    "eval_steps = len(x_test_tokenized) // BATCH_SIZE\n",
    "\n",
    "print(\"Training model...\")\n",
    "print(\"INFO: Epochs: \", EPOCHS, \". Batch size: \", BATCH_SIZE, \". Steps pr. epoch: \", n_steps, \". Eval steps: \", eval_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NutidsrModel' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NutidsrModel' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y):\n",
    "    indexes = random.sample(range(len(x)), BATCH_SIZE)\n",
    "    x_batch = [x[i] for i in indexes]\n",
    "    y_batch = [y[i] for i in indexes]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def train_model(xb, yb):\n",
    "    yb = Tensor([yb])\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(xb)\n",
    "    loss = (output * yb).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 257/1490 [00:45<03:39,  5.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(accuracies)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(accuracies))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[114], line 7\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     xb \u001b[38;5;241m=\u001b[39m Tensor(xb)\n\u001b[1;32m      6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward(xb))\n\u001b[0;32m----> 7\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(output)\n\u001b[1;32m      8\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(accuracies)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(accuracies))\n",
      "Cell \u001b[0;32mIn[114], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     xb \u001b[38;5;241m=\u001b[39m Tensor(xb)\n\u001b[1;32m      6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward(xb))\n\u001b[0;32m----> 7\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m y \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (o,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output, yb)])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(output)\n\u001b[1;32m      8\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(accuracies)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(accuracies))\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:106\u001b[0m, in \u001b[0;36mTensor.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazydata\u001b[39m.\u001b[39;49mtoCPU()\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/lazy.py:178\u001b[0m, in \u001b[0;36mLazyBuffer.toCPU\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtoCPU\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    177\u001b[0m   realized \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcast(dtypes\u001b[39m.\u001b[39mfrom_np(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnp))\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mrealize()\u001b[39m.\u001b[39mrealized\n\u001b[0;32m--> 178\u001b[0m   ret \u001b[39m=\u001b[39m cast(RawBuffer, realized)\u001b[39m.\u001b[39;49mtoCPU()\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    179\u001b[0m   \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/runtime/lib.py:47\u001b[0m, in \u001b[0;36mRawBufferCopyInOut.toCPU\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtoCPU\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     46\u001b[0m   x: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnp)\n\u001b[0;32m---> 47\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_copyout(x)\n\u001b[1;32m     48\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/runtime/ops_gpu.py:49\u001b[0m, in \u001b[0;36mCLBuffer._copyout\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_copyout\u001b[39m(\u001b[39mself\u001b[39m, x:np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     48\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt copyout images \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m   cl\u001b[39m.\u001b[39;49menqueue_copy(CL\u001b[39m.\u001b[39;49mcl_queue[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buf\u001b[39m.\u001b[39;49mdevice], x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buf, is_blocking\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pyopencl/__init__.py:2013\u001b[0m, in \u001b[0;36menqueue_copy\u001b[0;34m(queue, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m   2006\u001b[0m             warn(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdevice_offset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument of enqueue_copy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2007\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mis deprecated. Use \u001b[39m\u001b[39m'\u001b[39m\u001b[39msrc_offset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2008\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdst_offset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m will stop working in 2023.x.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2009\u001b[0m                     \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   2011\u001b[0m             kwargs[\u001b[39m\"\u001b[39m\u001b[39msrc_offset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m device_offset\n\u001b[0;32m-> 2013\u001b[0m         \u001b[39mreturn\u001b[39;00m _cl\u001b[39m.\u001b[39;49m_enqueue_read_buffer(queue, src, dest, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2015\u001b[0m \u001b[39melif\u001b[39;00m src\u001b[39m.\u001b[39mtype \u001b[39min\u001b[39;00m _IMAGE_MEM_OBJ_TYPES:\n\u001b[1;32m   2016\u001b[0m     origin \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39morigin\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_model():\n",
    "    accuracies = []\n",
    "    for i in tqdm(range(eval_steps)):\n",
    "        xb, yb = get_batch(x_test_tokenized, y_test)\n",
    "        xb = Tensor(xb)\n",
    "        output = list(model.forward(xb))\n",
    "        accuracy = sum([1 if o.numpy() == y else 0 for (o,y) in zip(output, yb)])/len(output)\n",
    "        accuracies.append(accuracy)\n",
    "    print(\"Eval accuracy: \", sum(accuracies)/len(accuracies))\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/13413 [00:00<36:01,  6.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: -0.2539061903953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2736/13413 [02:30<09:47, 18.17it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(x_train_tokenized, y_train)\n\u001b[1;32m      4\u001b[0m xb \u001b[38;5;241m=\u001b[39m Tensor(xb)\n\u001b[0;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss at step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[109], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(xb, yb)\u001b[0m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m (output \u001b[38;5;241m*\u001b[39m yb)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/nn/optim.py:59\u001b[0m, in \u001b[0;36mLAMB.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv[i]\u001b[39m.\u001b[39massign(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv[i] \u001b[39m+\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2) \u001b[39m*\u001b[39m (g \u001b[39m*\u001b[39m g))\u001b[39m.\u001b[39mrealize()\n\u001b[1;32m     58\u001b[0m m_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm[i] \u001b[39m/\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt)\n\u001b[0;32m---> 59\u001b[0m v_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv[i] \u001b[39m/\u001b[39m (\u001b[39m1.0\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb2\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt)\n\u001b[1;32m     60\u001b[0m up \u001b[39m=\u001b[39m (m_hat \u001b[39m/\u001b[39m (v_hat\u001b[39m.\u001b[39msqrt() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwd \u001b[39m*\u001b[39m t\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madam:\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:533\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, x)\u001b[0m\n\u001b[0;32m--> 533\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, x) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msub(x, \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:512\u001b[0m, in \u001b[0;36mTensor.sub\u001b[0;34m(self, x, reverse)\u001b[0m\n\u001b[0;32m--> 512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(\u001b[39mself\u001b[39m, x:Union[Tensor, \u001b[39mfloat\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_broadcasted(mlops\u001b[39m.\u001b[39;49mSub, x, reverse) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Tensor) \u001b[39mor\u001b[39;00m x \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m reverse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:507\u001b[0m, in \u001b[0;36mTensor._broadcasted\u001b[0;34m(self, fxn, other, reverse)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcasted\u001b[39m(\u001b[39mself\u001b[39m, fxn:Type[Function], other:Union[Tensor, \u001b[39mfloat\u001b[39m], reverse:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    506\u001b[0m   x,y \u001b[39m=\u001b[39m [Tensor(t, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, Tensor) \u001b[39melse\u001b[39;00m t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ([other,\u001b[39mself\u001b[39m] \u001b[39mif\u001b[39;00m reverse \u001b[39melse\u001b[39;00m [\u001b[39mself\u001b[39m,other])]\n\u001b[0;32m--> 507\u001b[0m   x,y \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39;49mreshape([\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49m(\u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(x\u001b[39m.\u001b[39;49mshape), \u001b[39mlen\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape))\u001b[39m-\u001b[39;49m\u001b[39mlen\u001b[39;49m(t\u001b[39m.\u001b[39;49mshape)) \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(t\u001b[39m.\u001b[39;49mshape)) \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m [x,y]]\n\u001b[1;32m    508\u001b[0m   shape_ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmax\u001b[39m(sx, sy) \u001b[39mfor\u001b[39;00m sx,sy \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    509\u001b[0m   \u001b[39mreturn\u001b[39;00m fxn\u001b[39m.\u001b[39mapply(x\u001b[39m.\u001b[39mexpand(shape_ret), y\u001b[39m.\u001b[39mexpand(shape_ret))\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:507\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcasted\u001b[39m(\u001b[39mself\u001b[39m, fxn:Type[Function], other:Union[Tensor, \u001b[39mfloat\u001b[39m], reverse:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    506\u001b[0m   x,y \u001b[39m=\u001b[39m [Tensor(t, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, Tensor) \u001b[39melse\u001b[39;00m t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ([other,\u001b[39mself\u001b[39m] \u001b[39mif\u001b[39;00m reverse \u001b[39melse\u001b[39;00m [\u001b[39mself\u001b[39m,other])]\n\u001b[0;32m--> 507\u001b[0m   x,y \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39;49mreshape([\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49m(\u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(x\u001b[39m.\u001b[39;49mshape), \u001b[39mlen\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape))\u001b[39m-\u001b[39;49m\u001b[39mlen\u001b[39;49m(t\u001b[39m.\u001b[39;49mshape)) \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(t\u001b[39m.\u001b[39;49mshape)) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m [x,y]]\n\u001b[1;32m    508\u001b[0m   shape_ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmax\u001b[39m(sx, sy) \u001b[39mfor\u001b[39;00m sx,sy \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    509\u001b[0m   \u001b[39mreturn\u001b[39;00m fxn\u001b[39m.\u001b[39mapply(x\u001b[39m.\u001b[39mexpand(shape_ret), y\u001b[39m.\u001b[39mexpand(shape_ret))\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:228\u001b[0m, in \u001b[0;36mTensor.reshape\u001b[0;34m(self, shape, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m new_shape \u001b[39m=\u001b[39m argfix(shape, \u001b[39m*\u001b[39margs)\n\u001b[1;32m    227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m new_shape, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzeros not allowed in shape \u001b[39m\u001b[39m{\u001b[39;00mnew_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m mlops\u001b[39m.\u001b[39;49mReshape\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m, shape\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(\u001b[39m-\u001b[39;49mprod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m prod(new_shape) \u001b[39mif\u001b[39;49;00m s \u001b[39m==\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m s \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m new_shape))\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/tensor.py:22\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(fxn, *x, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(fxn:Type[Function], \u001b[39m*\u001b[39mx:Tensor, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     21\u001b[0m   ctx \u001b[39m=\u001b[39m fxn(x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdevice, \u001b[39m*\u001b[39mx)\n\u001b[0;32m---> 22\u001b[0m   ret \u001b[39m=\u001b[39m Tensor(ctx\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m[t\u001b[39m.\u001b[39;49mlazydata \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m x], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), device\u001b[39m=\u001b[39mctx\u001b[39m.\u001b[39mdevice, requires_grad\u001b[39m=\u001b[39mctx\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m     23\u001b[0m   \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39mrequires_grad \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m Tensor\u001b[39m.\u001b[39mno_grad: ret\u001b[39m.\u001b[39m_ctx \u001b[39m=\u001b[39m ctx    \u001b[39m# used by autograd engine\u001b[39;00m\n\u001b[1;32m     24\u001b[0m   \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/mlops.py:156\u001b[0m, in \u001b[0;36mReshape.forward\u001b[0;34m(self, x, shape)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x:LazyBuffer, shape:ShapeType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LazyBuffer:\n\u001b[1;32m    155\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 156\u001b[0m   \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mmovement_op(MovementOps\u001b[39m.\u001b[39;49mRESHAPE, shape)\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/lazy.py:199\u001b[0m, in \u001b[0;36mLazyBuffer.movement_op\u001b[0;34m(self, op, arg)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mif\u001b[39;00m op \u001b[39m==\u001b[39m MovementOps\u001b[39m.\u001b[39mRESHAPE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m arg: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    198\u001b[0m \u001b[39m# TODO: look into why that copy is needed\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m local_st \u001b[39m=\u001b[39m ShapeTracker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape)\u001b[39m.\u001b[39;49mmovement_op(op, arg)\n\u001b[1;32m    201\u001b[0m \u001b[39m# instant nops\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m local_st\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m local_st\u001b[39m.\u001b[39mshape: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/shape/shapetracker.py:232\u001b[0m, in \u001b[0;36mShapeTracker.movement_op\u001b[0;34m(self, op, arg)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmovement_op\u001b[39m(\u001b[39mself\u001b[39m, op, arg:Union[Tuple[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], Tuple[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ShapeTracker:\n\u001b[1;32m    231\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(arg) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape) \u001b[39mor\u001b[39;00m op \u001b[39m==\u001b[39m MovementOps\u001b[39m.\u001b[39mRESHAPE), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marg \u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mop\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match dim of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m   dispatch[op](\u001b[39mself\u001b[39;49m, arg)\n\u001b[1;32m    233\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/shape/shapetracker.py:187\u001b[0m, in \u001b[0;36mShapeTracker.reshape\u001b[0;34m(self, new_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(\u001b[39mself\u001b[39m, new_shape: Tuple[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]):\n\u001b[1;32m    186\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m new_shape: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 187\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m x \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m new_shape), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape must be ints and can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain 0 or negative numbers \u001b[39m\u001b[39m{\u001b[39;00mnew_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m   \u001b[39massert\u001b[39;00m prod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m prod(new_shape), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reshape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mnew_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m   \u001b[39m# check if this is adding or removing 1s (only)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m   \u001b[39m# NOTE: this is optional, but removes most calls to (expensive!) merge_views (with mask, not optional)\u001b[39;00m\n",
      "File \u001b[0;32m~/tinygrad/tinygrad/shape/shapetracker.py:187\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(\u001b[39mself\u001b[39m, new_shape: Tuple[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]):\n\u001b[1;32m    186\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m new_shape: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 187\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m x \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m new_shape), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape must be ints and can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain 0 or negative numbers \u001b[39m\u001b[39m{\u001b[39;00mnew_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m   \u001b[39massert\u001b[39;00m prod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m prod(new_shape), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reshape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mnew_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m   \u001b[39m# check if this is adding or removing 1s (only)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m   \u001b[39m# NOTE: this is optional, but removes most calls to (expensive!) merge_views (with mask, not optional)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        xb, yb = get_batch(x_train_tokenized, y_train)\n",
    "        xb = Tensor(xb)\n",
    "        loss = train_model(xb, yb)\n",
    "        if i % 3000 == 0:\n",
    "            print(f\"Loss at step {i}: {-loss}\")\n",
    "    \n",
    "    print(f\"Done with Epoch {epoch}\")\n",
    "    print(\"Evaluating...\")\n",
    "\n",
    "    for i in tqdm(range(eval_steps)):\n",
    "        xb = Tensor(x_test_tokenized)\n",
    "        output = list(model.forward(xb))\n",
    "        print(\"Eval accuracy: \", sum([1 if o == y else 0 for (o,y) in zip(output, y_test)])/len(output))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
