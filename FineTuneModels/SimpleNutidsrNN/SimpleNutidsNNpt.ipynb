{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"EuroparlNutidsr_trainset_verbs.csv\"\n",
    "print(\"Loading df...\")\n",
    "df = pd.read_csv(filename, encoding=\"UTF-8\", sep=\";\")\n",
    "pos = list(df[\"comment_text\"].values)\n",
    "labels = list(df[\"label\"].values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pos, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "unique_pos = ['NOUN','PUNCT','VERB','PRON','NUM','ADP','X','<PAD>','CCONJ','PROPN','AUX','SCONJ','INTJ','ADV','ADJ','PART','SYM','DET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NutidsrTokenizer():\n",
    "    def __init__(self) -> None:\n",
    "        print(\"Initializing tokenizer...\")\n",
    "        self.tokenize_table = {x: i for i, x in enumerate(unique_pos)}\n",
    "        print(\"Tokenizer initialized.\")\n",
    "\n",
    "    def __call__(self, pos_list):\n",
    "        for pos_string in tqdm(pos_list):\n",
    "            splitted_pos = pos_string.split()\n",
    "            numbers = [self.tokenize_table[x] for x in splitted_pos]\n",
    "            yield [y for x in numbers for y in self._one_hot_encode(x)]\n",
    "    \n",
    "    def _one_hot_encode(self, number):\n",
    "        return [1 if i == number else 0 for i in range(18)]\n",
    "\n",
    "class NutidsrModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(NutidsrModel, self).__init__()\n",
    "        number_of_unique_pos = 18\n",
    "        number_of_pos_including_padding = 21\n",
    "        self.l1 = nn.Linear(number_of_pos_including_padding*number_of_unique_pos, 512)\n",
    "        self.l2 = nn.Linear(512, 512)\n",
    "        self.l3 = nn.Linear(512, 256)\n",
    "        self.l4 = nn.Linear(256, 128)\n",
    "        self.l5 = nn.Linear(128, 32)\n",
    "        self.l6 = nn.Linear(32, 1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        print(self.l1.weight.dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.l5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.l6(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "Tokenizer initialized.\n",
      "Tokenizing train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1716972/1716972 [01:27<00:00, 19601.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190775/190775 [00:06<00:00, 29603.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Tokenizing.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = NutidsrTokenizer()\n",
    "print(\"Tokenizing train...\")\n",
    "x_train_tokenized = list(tokenizer(X_train))\n",
    "print(\"Tokenizing test...\")\n",
    "x_test_tokenized = list(tokenizer(X_test))\n",
    "print(\"Done Tokenizing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "Training model...\n",
      "INFO: Epochs:  3 . Batch size:  32 . Steps pr. epoch:  53655 . Eval steps:  5961\n",
      "Total training steps:  160965\n",
      "Number of parameters:  2882\n"
     ]
    }
   ],
   "source": [
    "EPOCHS, BATCH_SIZE = 3, 32\n",
    "\n",
    "model = NutidsrModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0002, betas=(0.5, 0.999))\n",
    "device = \"cpu\"\n",
    "loss_fn = nn.MSELoss()\n",
    "torch.device(device)\n",
    "model.to(device)\n",
    "n_steps = len(x_train_tokenized) // BATCH_SIZE\n",
    "eval_steps = len(x_test_tokenized) // BATCH_SIZE\n",
    "\n",
    "print(\"Training model...\")\n",
    "print(\"INFO: Epochs: \", EPOCHS, \". Batch size: \", BATCH_SIZE, \". Steps pr. epoch: \", n_steps, \". Eval steps: \", eval_steps)\n",
    "print(\"Total training steps: \", n_steps*EPOCHS)\n",
    "print(\"Number of parameters: \", sum([len(param) for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y):\n",
    "    indexes = random.sample(range(len(x)), BATCH_SIZE)\n",
    "    x_batch = [x[i] for i in indexes]\n",
    "    y_batch = [y[i] for i in indexes]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def train_model(xb, yb):\n",
    "    yb = torch.tensor(yb, dtype=torch.float32)\n",
    "    optimizer.zero_grad()\n",
    "    xb = torch.tensor(xb, dtype=torch.float32)\n",
    "    output = model.forward(xb)\n",
    "    loss = loss_fn(output, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test_model(eval_accuracies):\n",
    "    accuracies = []\n",
    "    for _ in tqdm(range(eval_steps)):\n",
    "        xb, yb = get_batch(x_test_tokenized, y_test)\n",
    "        xb = torch.tensor(xb, dtype=torch.float32)\n",
    "        output = list(model.forward(xb))\n",
    "        accuracy = sum([1 if to_binary(o) == y else 0 for (o,y) in zip(output, yb)])/len(output)\n",
    "        accuracies.append(accuracy)\n",
    "        del xb, yb, output, accuracy\n",
    "    eval_accuracies.append(round(sum(accuracies)/len(accuracies)*100, 2))\n",
    "    print(\"Eval accuracy: \", round(sum(accuracies)/len(accuracies)*100, 2), \"%\")\n",
    "    return eval_accuracies\n",
    "\n",
    "def to_binary(o):\n",
    "    return 1 if float(o) > 0.5 else 0\n",
    "\n",
    "def save_model(epoch):\n",
    "    os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/FineTuneModels/SimpleNutidsrNN/\")\n",
    "    os.makedirs(\"simpleNNmodelsPT\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"simpleNNmodelsPT/model_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5961/5961 [00:08<00:00, 730.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy:  57.34 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_accuracy = []\n",
    "losses = []\n",
    "\n",
    "print(\"Accuracy before training: \")\n",
    "eval_accuracy = test_model(eval_accuracy)\n",
    "save_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/53655 [00:00<?, ?it/s]/var/folders/pl/7f1cr2657p3bnpdt3bnm_9w00000gn/T/ipykernel_64887/693126525.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb = torch.tensor(xb, dtype=torch.float32)\n",
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 37/53655 [00:00<04:50, 184.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.2540414035320282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3025/53655 [00:16<04:11, 201.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 0.245047217592597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6032/53655 [00:30<03:52, 204.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6000: 0.24456610860427222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9024/53655 [00:45<03:35, 207.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9000: 0.24471970610320568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 12031/53655 [01:00<03:20, 207.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12000: 0.2444859666377306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 15031/53655 [01:14<03:06, 207.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15000: 0.24474409765998523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 18042/53655 [01:29<02:49, 209.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18000: 0.24494847591221333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 21026/53655 [01:43<02:39, 204.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21000: 0.24471258981029193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 24036/53655 [01:58<02:24, 205.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24000: 0.24476888142029443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 27040/53655 [02:12<02:13, 198.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27000: 0.24439825842281182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 30037/53655 [02:26<01:57, 200.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30000: 0.24475849476456643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 33037/53655 [02:41<01:37, 212.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33000: 0.24494650533795356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 36030/53655 [02:55<01:24, 208.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36000: 0.24447959209481876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 39041/53655 [03:10<01:09, 210.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39000: 0.24437103914717834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 42040/53655 [03:24<00:55, 208.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42000: 0.2445868814835946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 45028/53655 [03:38<00:41, 209.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45000: 0.24434785095850628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 48031/53655 [03:53<00:26, 210.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48000: 0.24472022205094496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 51024/53655 [04:07<00:12, 205.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51000: 0.2446924748023351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53655/53655 [04:20<00:00, 206.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Epoch 0\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5961/5961 [00:07<00:00, 803.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy:  57.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/53655 [00:00<04:35, 194.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.23887954652309418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3031/53655 [00:14<04:02, 209.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 0.24492711263398328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 6038/53655 [00:29<03:48, 208.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6000: 0.24486575757463774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9038/53655 [00:43<03:34, 208.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9000: 0.24467285052438578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 12022/53655 [00:58<05:02, 137.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12000: 0.2449960648616155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 12247/53655 [01:00<03:23, 203.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_steps)):\n\u001b[1;32m      5\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m get_batch(x_train_tokenized, y_train)\n\u001b[0;32m----> 6\u001b[0m     xb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_model(xb, yb)\n\u001b[1;32m      8\u001b[0m     temp_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    temp_losses = []\n",
    "    model.train()\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        xb, yb = get_batch(x_train_tokenized, y_train)\n",
    "        xb = torch.tensor(xb)\n",
    "        loss = train_model(xb, yb)\n",
    "        temp_losses.append(float(loss))\n",
    "        if i % 3000 == 0:\n",
    "            if len(temp_losses) > 0:\n",
    "                losses.append(sum(temp_losses)/len(temp_losses))\n",
    "                print(f\"Loss at step {i}: {sum(temp_losses)/len(temp_losses)}\")\n",
    "            temp_losses = []\n",
    "    \n",
    "    print(f\"Done with Epoch {epoch}\")\n",
    "    print(\"Evaluating...\")\n",
    "    model.eval()\n",
    "\n",
    "    eval_accuracy = test_model(eval_accuracy)\n",
    "    save_model(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.title(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval_accuracy)\n",
    "plt.title(\"Eval accuracy over time\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
