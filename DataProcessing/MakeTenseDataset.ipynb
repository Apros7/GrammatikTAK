{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r.pickle\", \"rb\") as f:\n",
    "    nutids_r = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 656266/656266 [00:02<00:00, 300917.44it/s]\n",
      "100%|██████████| 328134/328134 [00:27<00:00, 11830.82it/s] \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "step_rates = [1, 2, 3]\n",
    "pre_pad_result = []\n",
    "len_of_list = int(len(lines))\n",
    "for i in tqdm(range(0, len_of_list//3,step_rates[0])):\n",
    "    pre_pad_result.append((' '.join(lines[i:i+step_rates[0]])).split())\n",
    "for i in tqdm(range(len_of_list//3, 2*len_of_list//3,step_rates[1])):\n",
    "    pre_pad_result.append((' '.join(lines[i:i+step_rates[1]])).split())\n",
    "\n",
    "random.shuffle(pre_pad_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = 10\n",
    "middle = int(scope/2)\n",
    "padding = int(scope/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984400/984400 [00:39<00:00, 24998.00it/s] \n"
     ]
    }
   ],
   "source": [
    "pre_cleaned_result = [[\"<PAD>\"]*padding + lst + [\"<PAD>\"]*padding for lst in tqdm(pre_pad_result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984400/984400 [01:21<00:00, 12106.52it/s]\n"
     ]
    }
   ],
   "source": [
    "char = \"*@;:!\\\"?«».,\"\n",
    "post_pad_result = [[word.translate(str.maketrans('', '', ''.join(char))) for word in pre_cleaned_lst] for pre_cleaned_lst in tqdm(pre_cleaned_result)]\n",
    "\n",
    "# for i in tqdm(range(len(pre_cleaned_result))):\n",
    "#     pre_cleaned_lst = pre_cleaned_result[i]\n",
    "#     lst = [word.translate(str.maketrans('', '', ''.join(char))) for word in pre_cleaned_lst]\n",
    "#     post_pad_result.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_post_pad_result = post_pad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pad_result = saved_post_pad_result[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 37801.45it/s]\n"
     ]
    }
   ],
   "source": [
    "bøjning = {0: \"infinitiv\", 1: \"førnutidsformen\"}\n",
    "half_scope = int(scope/2)\n",
    "big_lst = []\n",
    "output_lst = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(post_pad_result))):\n",
    "    current_lst = post_pad_result[i]\n",
    "    for x in range(len(current_lst)):\n",
    "        current_word = current_lst[x]\n",
    "        try: stemmed_word = nutids_r_stem[current_word]\n",
    "        except: continue\n",
    "        current_dataset = current_lst[x-half_scope:x+half_scope+1]\n",
    "        try: current_dataset[half_scope] = stemmed_word\n",
    "        except: print(current_dataset); continue\n",
    "        big_lst.append((\" \".join(current_dataset)).lower())\n",
    "        if nutids_r[stemmed_word][0] == current_word:\n",
    "            output = 0\n",
    "        elif nutids_r[stemmed_word][1] == current_word:\n",
    "            output = 1\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "        output_lst.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143961\n",
      "0    92156\n",
      "1    51805\n",
      "Name: label, dtype: int64\n",
      "143961\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"comment_text\"] = big_lst\n",
    "df[\"label\"] = output_lst\n",
    "\n",
    "print(len(df))\n",
    "df = df[:6000000]\n",
    "\n",
    "def distribution(df):\n",
    "    print(df[\"label\"].value_counts())\n",
    "\n",
    "distribution(df)\n",
    "print(len(df))\n",
    "header = [\"comment_text\", \"label\"]\n",
    "df.to_csv(\"../Datasets/EuroparlNutidsr.csv\", encoding=\"UTF-8\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Making testset for nutids-r module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r_bøjninger.pickle\", \"rb\") as f:\n",
    "    nutids_r_bøjninger = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/894 [02:18<1:40:50,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "Fru formand, da jeg kan høre en smule latter fra Socialdemokraterne - jeg har fået fortalt, at brede kredse i Den Socialdemokratiske Gruppe også gerne vil have taget dette punkt af dagsordenen, fordi der ved afstemningen på Formandskonferencen ikke forelå noget votum fra arbejdsgruppen af ansvarlige kolleger i Den Socialdemokratiske Gruppe.\n",
      "kan -> kunne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/894 [02:20<2:08:02,  8.75s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     bøjet_ord \u001b[38;5;241m=\u001b[39m nutids_r_bøjninger[stemmed][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbøjet_ord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m to_continue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1 for Ja, 2 for Nej.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m clear_output()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_continue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/EuroparlNutidsr_testset.csv\", encoding=\"UTF-8\", sep=\";\")\n",
    "correct_sentences = list(df[\"correct\"])\n",
    "wrong_sentences = list(df[\"wrong\"])\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def save_df():\n",
    "    df = pd.DataFrame()\n",
    "    df[\"wrong\"] = wrong_sentences\n",
    "    df[\"correct\"] = correct_sentences\n",
    "    df.to_csv(\"../Datasets/EuroparlNutidsr_testset.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "\n",
    "for line in tqdm(lines[122:1000]):\n",
    "    line = line.strip(\"\\n\")\n",
    "    words = line.split()\n",
    "    for i, word in enumerate(words):\n",
    "        print(\"hey\")\n",
    "        symbol = \"\"\n",
    "        if word[-1] in \".,?!\":\n",
    "            symbol = word[-1]\n",
    "            word = word[:-1]\n",
    "        try: stemmed = nutids_r_stem[word]\n",
    "        except: continue\n",
    "        if word[-1] == \"s\":\n",
    "            continue\n",
    "        print(line)\n",
    "        if nutids_r_bøjninger[stemmed][0] == word:\n",
    "            bøjet_ord = nutids_r_bøjninger[stemmed][1]\n",
    "        else:\n",
    "            bøjet_ord = nutids_r_bøjninger[stemmed][0]\n",
    "        print(f\"{word} -> {bøjet_ord}\")\n",
    "        to_continue = int(input(f\"1 for Ja, 2 for Nej.\"))\n",
    "        clear_output()\n",
    "        if to_continue == 2:\n",
    "            continue\n",
    "        words[i] = bøjet_ord + symbol\n",
    "    new_line = \" \".join(words)\n",
    "    wrong_sentences.append(new_line)\n",
    "    correct_sentences.append(line)\n",
    "    save_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r_bøjninger.pickle\", \"rb\") as f:\n",
    "    nutids_r_bøjninger = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If changed all of the dataset also needs to be changed\n",
    "\n",
    "scope = 10\n",
    "padding = int(scope/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; CCONJ NOUN ADP NOUN ADP PROPN PRON...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; SCONJ PRON VERB ADP NO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; SCONJ PRON VERB ADP NOUN ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERB ADP NOUN ADP NOUN ADV AUX NOUN ADP DET NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292324</th>\n",
       "      <td>NOUN ADP ADJ NOUN NOUN VERB ADV NOUN ADP DET NOUN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292325</th>\n",
       "      <td>PRON PRON ADV ADV AUX VERB ADP DET ADJ NOUN &lt;PAD&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292326</th>\n",
       "      <td>NOUN SCONJ DET NOUN AUX AUX VERB ADV ADP NOUN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292327</th>\n",
       "      <td>DET NOUN NOUN ADP NOUN VERB ADP PUNCT CCONJ PR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292328</th>\n",
       "      <td>VERB ADP PUNCT CCONJ PRON VERB DET ADJ PUNCT &lt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  label\n",
       "0       <PAD> <PAD> CCONJ NOUN ADP NOUN ADP PROPN PRON...      1\n",
       "1       ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...      0\n",
       "2       <PAD> <PAD> <PAD> <PAD> SCONJ PRON VERB ADP NO...      1\n",
       "3       <PAD> <PAD> <PAD> SCONJ PRON VERB ADP NOUN ADP...      0\n",
       "4        VERB ADP NOUN ADP NOUN ADV AUX NOUN ADP DET NOUN      1\n",
       "...                                                   ...    ...\n",
       "292324  NOUN ADP ADJ NOUN NOUN VERB ADV NOUN ADP DET NOUN      0\n",
       "292325  PRON PRON ADV ADV AUX VERB ADP DET ADJ NOUN <PAD>      1\n",
       "292326  NOUN SCONJ DET NOUN AUX AUX VERB ADV ADP NOUN ...      1\n",
       "292327  DET NOUN NOUN ADP NOUN VERB ADP PUNCT CCONJ PR...      0\n",
       "292328  VERB ADP PUNCT CCONJ PRON VERB DET ADJ PUNCT <...      0\n",
       "\n",
       "[292329 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/EuroparlNutidsr_trainset.csv\", encoding=\"UTF-8\", sep=\";\")\n",
    "testset = list(df[\"comment_text\"])\n",
    "labels = list(df[\"label\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 13:49:42 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73466223bf0492ebbbb8a5b9be036e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 13:49:42 INFO: Loading these models for language: da (Danish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ddt     |\n",
      "| pos       | ddt     |\n",
      "=======================\n",
      "\n",
      "2023-05-04 13:49:42 WARNING: GPU requested, but is not available!\n",
      "2023-05-04 13:49:42 INFO: Using device: cpu\n",
      "2023-05-04 13:49:42 INFO: Loading: tokenize\n",
      "2023-05-04 13:49:42 INFO: Loading: pos\n",
      "2023-05-04 13:49:43 INFO: Done loading processors!\n",
      "100%|██████████| 13000/13000 [37:50<00:00,  5.73it/s] \n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "pos_model = stanza.Pipeline(\"da\", processors='tokenize,pos', use_gpu=True, cache_directory='./cache', tokenize_pretokenized=True, n_process=8)\n",
    "\n",
    "def get_pos_tags(words):\n",
    "    doc = pos_model(\" \".join(words))\n",
    "    results = [word.upos for sentence in doc.sentences for i, word in enumerate(sentence.words)]\n",
    "    return results\n",
    "\n",
    "# Already done up to 143.000\n",
    "\n",
    "for line in tqdm(lines[130000:143000]):\n",
    "    line = line.strip(\"\\n\")\n",
    "    true_words = line.split()\n",
    "    pos = get_pos_tags(true_words)\n",
    "    words = [\"<PAD>\"]*padding + pos + [\"<PAD>\"]*padding\n",
    "    for i, word in enumerate(true_words):\n",
    "        try: stemmed = nutids_r_stem[word]\n",
    "        except: continue\n",
    "        if word[-1] == \"s\":\n",
    "            continue\n",
    "        if nutids_r_bøjninger[stemmed][0] == word:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        testset.append(\" \".join(words[i:i+2*padding+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(testset, labels), columns=[\"comment_text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; CCONJ NOUN ADP NOUN ADP PROPN PRON...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; SCONJ PRON VERB ADP NO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; SCONJ PRON VERB ADP NOUN ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERB ADP NOUN ADP NOUN ADV AUX NOUN ADP DET NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320113</th>\n",
       "      <td>CCONJ SCONJ PRON AUX VERB ADP NOUN PUNCT &lt;PAD&gt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320114</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; ADV AUX PRON ADP NOUN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320115</th>\n",
       "      <td>VERB ADP NOUN ADJ NOUN VERB NOUN DET ADJ NOUN ADP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320116</th>\n",
       "      <td>PRON PUNCT PRON PRON VERB VERB ADJ NOUN ADP NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320117</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; NOUN VERB PRON ADV ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  label\n",
       "0       <PAD> <PAD> CCONJ NOUN ADP NOUN ADP PROPN PRON...      1\n",
       "1       ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...      0\n",
       "2       <PAD> <PAD> <PAD> <PAD> SCONJ PRON VERB ADP NO...      1\n",
       "3       <PAD> <PAD> <PAD> SCONJ PRON VERB ADP NOUN ADP...      0\n",
       "4        VERB ADP NOUN ADP NOUN ADV AUX NOUN ADP DET NOUN      1\n",
       "...                                                   ...    ...\n",
       "320113  CCONJ SCONJ PRON AUX VERB ADP NOUN PUNCT <PAD>...      0\n",
       "320114  <PAD> <PAD> <PAD> <PAD> ADV AUX PRON ADP NOUN ...      0\n",
       "320115  VERB ADP NOUN ADJ NOUN VERB NOUN DET ADJ NOUN ADP      0\n",
       "320116  PRON PUNCT PRON PRON VERB VERB ADJ NOUN ADP NO...      0\n",
       "320117  <PAD> <PAD> <PAD> <PAD> NOUN VERB PRON ADV ADP...      0\n",
       "\n",
       "[320118 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN :  24172\n",
      "VERB :  196743\n",
      "PRON :  29802\n",
      "ADV :  8086\n",
      "AUX :  35093\n",
      "ADJ :  12606\n",
      "NUM :  3310\n",
      "SCONJ :  6164\n",
      "ADP :  4073\n",
      "X :  67\n",
      "INTJ :  1\n",
      "PROPN :  1\n"
     ]
    }
   ],
   "source": [
    "comment_text = df[\"comment_text\"].values\n",
    "mistakes = [l for l in comment_text if not l.isupper()]\n",
    "middle = [l.split()[5] for l in comment_text]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(middle)\n",
    "for key, value in counter.items():\n",
    "    print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Datasets/EuroparlNutidsr_trainset.csv\", encoding=\"UTF-8\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; SCONJ PRON VERB ADP NOUN ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADP NOUN VERB ADP PART VERB DET ADJ NOUN PUNCT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; PRON VERB ADJ NOUN ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOUN CCONJ PRON AUX ADV VERB PRON &lt;PAD&gt; &lt;PAD&gt; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196738</th>\n",
       "      <td>NOUN ADP NOUN ADP PART VERB DET ADJ PUNCT PRON...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196739</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; PRON VERB ADV ADP DET ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196740</th>\n",
       "      <td>VERB ADP NOUN ADJ NOUN VERB NOUN DET ADJ NOUN ADP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196741</th>\n",
       "      <td>PRON PUNCT PRON PRON VERB VERB ADJ NOUN ADP NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196742</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; NOUN VERB PRON ADV ADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  label\n",
       "0       ADP NOUN ADP PROPN PRON VERB ADP NOUN ADP NOUN...      0\n",
       "1       <PAD> <PAD> <PAD> SCONJ PRON VERB ADP NOUN ADP...      0\n",
       "2       ADP NOUN VERB ADP PART VERB DET ADJ NOUN PUNCT...      1\n",
       "3       <PAD> <PAD> <PAD> <PAD> PRON VERB ADJ NOUN ADP...      0\n",
       "4       NOUN CCONJ PRON AUX ADV VERB PRON <PAD> <PAD> ...      1\n",
       "...                                                   ...    ...\n",
       "196738  NOUN ADP NOUN ADP PART VERB DET ADJ PUNCT PRON...      1\n",
       "196739  <PAD> <PAD> <PAD> <PAD> PRON VERB ADV ADP DET ...      0\n",
       "196740  VERB ADP NOUN ADJ NOUN VERB NOUN DET ADJ NOUN ADP      0\n",
       "196741  PRON PUNCT PRON PRON VERB VERB ADJ NOUN ADP NO...      0\n",
       "196742  <PAD> <PAD> <PAD> <PAD> NOUN VERB PRON ADV ADP...      0\n",
       "\n",
       "[196743 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_text_and_labels = [(c, l) for c, l in zip(comment_text, labels) if c.split()[5] == \"VERB\"]\n",
    "verb_text = [c for c, l in verb_text_and_labels]\n",
    "verb_labels = [l for c, l in verb_text_and_labels]\n",
    "\n",
    "df = pd.DataFrame(zip(verb_text, verb_labels), columns=[\"comment_text\", \"label\"])\n",
    "df.to_csv(\"../Datasets/EuroparlNutidsr_trainset_verbs.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
