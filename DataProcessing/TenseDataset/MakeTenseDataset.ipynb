{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r.pickle\", \"rb\") as f:\n",
    "    nutids_r = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 656266/656266 [00:03<00:00, 209555.94it/s]\n",
      "100%|██████████| 328134/328134 [00:02<00:00, 163102.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "step_rates = [1, 2, 3]\n",
    "pre_pad_result = []\n",
    "len_of_list = int(len(lines))\n",
    "for i in tqdm(range(0, len_of_list//3,step_rates[0])):\n",
    "    pre_pad_result.append((' '.join(lines[i:i+step_rates[0]])).split())\n",
    "for i in tqdm(range(len_of_list//3, 2*len_of_list//3,step_rates[1])):\n",
    "    pre_pad_result.append((' '.join(lines[i:i+step_rates[1]])).split())\n",
    "\n",
    "random.shuffle(pre_pad_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = 10\n",
    "middle = int(scope/2)\n",
    "padding = int(scope/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984400/984400 [00:39<00:00, 24998.00it/s] \n"
     ]
    }
   ],
   "source": [
    "pre_cleaned_result = [[\"<PAD>\"]*padding + lst + [\"<PAD>\"]*padding for lst in tqdm(pre_pad_result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984400/984400 [01:21<00:00, 12106.52it/s]\n"
     ]
    }
   ],
   "source": [
    "char = \"*@;:!\\\"?«».,\"\n",
    "post_pad_result = [[word.translate(str.maketrans('', '', ''.join(char))) for word in pre_cleaned_lst] for pre_cleaned_lst in tqdm(pre_cleaned_result)]\n",
    "\n",
    "# for i in tqdm(range(len(pre_cleaned_result))):\n",
    "#     pre_cleaned_lst = pre_cleaned_result[i]\n",
    "#     lst = [word.translate(str.maketrans('', '', ''.join(char))) for word in pre_cleaned_lst]\n",
    "#     post_pad_result.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_post_pad_result = post_pad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pad_result = saved_post_pad_result[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 37801.45it/s]\n"
     ]
    }
   ],
   "source": [
    "bøjning = {0: \"infinitiv\", 1: \"førnutidsformen\"}\n",
    "half_scope = int(scope/2)\n",
    "big_lst = []\n",
    "output_lst = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(post_pad_result))):\n",
    "    current_lst = post_pad_result[i]\n",
    "    for x in range(len(current_lst)):\n",
    "        current_word = current_lst[x]\n",
    "        try: stemmed_word = nutids_r_stem[current_word]\n",
    "        except: continue\n",
    "        current_dataset = current_lst[x-half_scope:x+half_scope+1]\n",
    "        try: current_dataset[half_scope] = stemmed_word\n",
    "        except: print(current_dataset); continue\n",
    "        big_lst.append((\" \".join(current_dataset)).lower())\n",
    "        if nutids_r[stemmed_word][0] == current_word:\n",
    "            output = 0\n",
    "        elif nutids_r[stemmed_word][1] == current_word:\n",
    "            output = 1\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "        output_lst.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143961\n",
      "0    92156\n",
      "1    51805\n",
      "Name: label, dtype: int64\n",
      "143961\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"comment_text\"] = big_lst\n",
    "df[\"label\"] = output_lst\n",
    "\n",
    "print(len(df))\n",
    "df = df[:6000000]\n",
    "\n",
    "def distribution(df):\n",
    "    print(df[\"label\"].value_counts())\n",
    "\n",
    "distribution(df)\n",
    "print(len(df))\n",
    "header = [\"comment_text\", \"label\"]\n",
    "df.to_csv(\"../Datasets/EuroparlNutidsr.csv\", encoding=\"UTF-8\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Making testset for nutids-r module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r_bøjninger.pickle\", \"rb\") as f:\n",
    "    nutids_r_bøjninger = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/894 [02:18<1:40:50,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "Fru formand, da jeg kan høre en smule latter fra Socialdemokraterne - jeg har fået fortalt, at brede kredse i Den Socialdemokratiske Gruppe også gerne vil have taget dette punkt af dagsordenen, fordi der ved afstemningen på Formandskonferencen ikke forelå noget votum fra arbejdsgruppen af ansvarlige kolleger i Den Socialdemokratiske Gruppe.\n",
      "kan -> kunne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/894 [02:20<2:08:02,  8.75s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     bøjet_ord \u001b[38;5;241m=\u001b[39m nutids_r_bøjninger[stemmed][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbøjet_ord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m to_continue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1 for Ja, 2 for Nej.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m clear_output()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_continue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/EuroparlNutidsr_testset.csv\", encoding=\"UTF-8\", sep=\";\")\n",
    "correct_sentences = list(df[\"correct\"])\n",
    "wrong_sentences = list(df[\"wrong\"])\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def save_df():\n",
    "    df = pd.DataFrame()\n",
    "    df[\"wrong\"] = wrong_sentences\n",
    "    df[\"correct\"] = correct_sentences\n",
    "    df.to_csv(\"../Datasets/EuroparlNutidsr_testset.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "\n",
    "for line in tqdm(lines[122:1000]):\n",
    "    line = line.strip(\"\\n\")\n",
    "    words = line.split()\n",
    "    for i, word in enumerate(words):\n",
    "        print(\"hey\")\n",
    "        symbol = \"\"\n",
    "        if word[-1] in \".,?!\":\n",
    "            symbol = word[-1]\n",
    "            word = word[:-1]\n",
    "        try: stemmed = nutids_r_stem[word]\n",
    "        except: continue\n",
    "        if word[-1] == \"s\":\n",
    "            continue\n",
    "        print(line)\n",
    "        if nutids_r_bøjninger[stemmed][0] == word:\n",
    "            bøjet_ord = nutids_r_bøjninger[stemmed][1]\n",
    "        else:\n",
    "            bøjet_ord = nutids_r_bøjninger[stemmed][0]\n",
    "        print(f\"{word} -> {bøjet_ord}\")\n",
    "        to_continue = int(input(f\"1 for Ja, 2 for Nej.\"))\n",
    "        clear_output()\n",
    "        if to_continue == 2:\n",
    "            continue\n",
    "        words[i] = bøjet_ord + symbol\n",
    "    new_line = \" \".join(words)\n",
    "    wrong_sentences.append(new_line)\n",
    "    correct_sentences.append(line)\n",
    "    save_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"nutids_r_bøjninger.pickle\", \"rb\") as f:\n",
    "    nutids_r_bøjninger = pickle.load(f)\n",
    "with open(\"nutids_r_stem.pickle\", \"rb\") as f:\n",
    "    nutids_r_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If changed all of the dataset also needs to be changed\n",
    "\n",
    "padding_left = 15\n",
    "padding_right = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "labels = []\n",
    "testset_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genoptagelse af sessionen</td>\n",
       "      <td>NOUN ADP NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeg erklærer Europa-Parlamentets session, der ...</td>\n",
       "      <td>PRON VERB NOUN PUNCT PRON AUX VERB NOUN DET AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Som De kan se, indfandt det store \"år 2000-pro...</td>\n",
       "      <td>ADP PRON AUX VERB VERB DET ADJ NOUN X PRON PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>De har udtrykt ønske om en debat om dette emne...</td>\n",
       "      <td>PRON AUX VERB NOUN ADP DET NOUN ADP DET NOUN A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I mellemtiden ønsker jeg - som også en del kol...</td>\n",
       "      <td>ADP NOUN VERB PRON PUNCT ADP ADV DET NOUN NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399995</th>\n",
       "      <td>Derfor opfordrer jeg den italienske regering t...</td>\n",
       "      <td>ADV VERB PRON DET ADJ NOUN ADP PART VERB NOUN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399996</th>\n",
       "      <td>Sidstnævnte bør overvåge denne afgørelse nøje ...</td>\n",
       "      <td>ADJ AUX VERB DET NOUN ADV CCONJ ADP ADJ VERB N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399997</th>\n",
       "      <td>Strukturfondene, som i øjeblikket er indefross...</td>\n",
       "      <td>PUNCT ADP ADP NOUN AUX VERB ADP NOUN AUX PUNCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399998</th>\n",
       "      <td>Hvad angår placering af nye affaldsindsamlings...</td>\n",
       "      <td>PRON VERB NOUN ADP ADJ NOUN AUX ADV VERB ADJ N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399999</th>\n",
       "      <td>Jeg vil gerne understrege behovet for at genop...</td>\n",
       "      <td>PRON AUX ADV VERB NOUN ADP PART VERB ADJ NOUN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1397842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sent  \\\n",
       "0                                Genoptagelse af sessionen   \n",
       "1        Jeg erklærer Europa-Parlamentets session, der ...   \n",
       "2        Som De kan se, indfandt det store \"år 2000-pro...   \n",
       "3        De har udtrykt ønske om en debat om dette emne...   \n",
       "4        I mellemtiden ønsker jeg - som også en del kol...   \n",
       "...                                                    ...   \n",
       "1399995  Derfor opfordrer jeg den italienske regering t...   \n",
       "1399996  Sidstnævnte bør overvåge denne afgørelse nøje ...   \n",
       "1399997  Strukturfondene, som i øjeblikket er indefross...   \n",
       "1399998  Hvad angår placering af nye affaldsindsamlings...   \n",
       "1399999  Jeg vil gerne understrege behovet for at genop...   \n",
       "\n",
       "                                                       pos  \n",
       "0                                            NOUN ADP NOUN  \n",
       "1        PRON VERB NOUN PUNCT PRON AUX VERB NOUN DET AD...  \n",
       "2        ADP PRON AUX VERB VERB DET ADJ NOUN X PRON PUN...  \n",
       "3        PRON AUX VERB NOUN ADP DET NOUN ADP DET NOUN A...  \n",
       "4        ADP NOUN VERB PRON PUNCT ADP ADV DET NOUN NOUN...  \n",
       "...                                                    ...  \n",
       "1399995  ADV VERB PRON DET ADJ NOUN ADP PART VERB NOUN ...  \n",
       "1399996  ADJ AUX VERB DET NOUN ADV CCONJ ADP ADJ VERB N...  \n",
       "1399997  PUNCT ADP ADP NOUN AUX VERB ADP NOUN AUX PUNCT...  \n",
       "1399998  PRON VERB NOUN ADP ADJ NOUN AUX ADV VERB ADJ N...  \n",
       "1399999  PRON AUX ADV VERB NOUN ADP PART VERB ADJ NOUN ...  \n",
       "\n",
       "[1397842 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/EuroparlSentToPos.csv\", encoding=\"UTF-8\", sep=\";\")\n",
    "df_filtered = df.dropna(subset=[\"pos\"])\n",
    "sentences = list(df_filtered[\"sent\"])\n",
    "all_pos = list(df_filtered[\"pos\"])\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1397842/1397842 [00:31<00:00, 44424.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_pos_tags(index):\n",
    "    return all_pos[index].split()\n",
    "\n",
    "for i in tqdm(range(len(sentences))):\n",
    "    line = sentences[i]\n",
    "    if len(str(line)) < 1 or str(line) == \"nan\":\n",
    "        continue\n",
    "    line = line.strip(\"\\n\")\n",
    "    true_words = line.split()\n",
    "    pos = get_pos_tags(i)\n",
    "    words = [\"<PAD>\"]*padding_left + pos + [\"<PAD>\"]*padding_right\n",
    "    words_with_padding = [\"<PAD>\"]*padding_left + true_words + [\"<PAD>\"]*padding_right\n",
    "    for i, word in enumerate(true_words):\n",
    "        try: stemmed = nutids_r_stem[word]\n",
    "        except: continue\n",
    "        if word[-1] == \"s\":\n",
    "            continue\n",
    "        if nutids_r_bøjninger[stemmed][0] == word:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        testset.append(\" \".join(words[i:i+padding_left+padding_right+1]))\n",
    "        current_words = words_with_padding[i:i+padding_left+padding_right+1]\n",
    "        current_words[padding_left] = \"[MASK]\"\n",
    "        if words[i+padding_left] == \"VERB\":\n",
    "            testset_words.append(\" \".join(current_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> Jeg [MASK] Europa-Parlamentets session, der blev afbrudt',\n",
       " 'session, der blev afbrudt fredag den 17. december, for genoptaget. Endnu en gang vil jeg [MASK] Dem godt nytår, og jeg',\n",
       " '<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> I mellemtiden [MASK] jeg - som også en',\n",
       " 'mellemtiden ønsker jeg - som også en del kolleger har anmodet om - at vi [MASK] et minuts stilhed til minde',\n",
       " '<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> Jeg [MASK] Dem til stående at iagttage',\n",
       " '<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> Jeg opfordrer Dem til stående at [MASK] et minuts stilhed. <PAD> <PAD>',\n",
       " 'være passende, hvis De, fru formand, sendte en skrivelse til Sri Lankas præsident for at [MASK] vores dybe beklagelse i forbindelse',\n",
       " 'Kumar Ponnambalams død og de andre voldsomme dødsfald i Sri Lanka og for indtrængende at [MASK] præsidenten om at gøre alt',\n",
       " 'de andre voldsomme dødsfald i Sri Lanka og for indtrængende at anmode præsidenten om at [MASK] alt for at opnå en',\n",
       " 'i Sri Lanka og for indtrængende at anmode præsidenten om at gøre alt for at [MASK] en fredelig løsning på en']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUNCT PRON AUX VERB NOUN DET ADJ NOUN ADP PUNC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091192</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; PUNCT ADP ADP NO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091193</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091194</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091195</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091196</th>\n",
       "      <td>ADP DET ADJ NOUN CCONJ DET ADJ NOUN PRON ADV A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3091197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  label\n",
       "0        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "1        PUNCT PRON AUX VERB NOUN DET ADJ NOUN ADP PUNC...      1\n",
       "2        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "3        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "4        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "...                                                    ...    ...\n",
       "3091192  <PAD> <PAD> <PAD> <PAD> <PAD> PUNCT ADP ADP NO...      1\n",
       "3091193  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "3091194  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "3091195  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "3091196  ADP DET ADJ NOUN CCONJ DET ADJ NOUN PRON ADV A...      1\n",
       "\n",
       "[3091197 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(testset, labels), columns=[\"comment_text\", \"label\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NOUN',\n",
       "  'PUNCT',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'NUM',\n",
       "  'ADP',\n",
       "  'X',\n",
       "  '<PAD>',\n",
       "  'CCONJ',\n",
       "  'PROPN',\n",
       "  'AUX',\n",
       "  'SCONJ',\n",
       "  'INTJ',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'PART',\n",
       "  'SYM',\n",
       "  'DET'],\n",
       " 18)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos = list(set([x for test in testset for x in test.split()]))\n",
    "all_pos, len(all_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1957938\n",
       "0    1133259\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB :  1907747\n",
      "AUX :  335583\n",
      "NOUN :  243805\n",
      "PRON :  297064\n",
      "ADJ :  117935\n",
      "ADV :  64485\n",
      "SCONJ :  53839\n",
      "NUM :  31007\n",
      "ADP :  39344\n",
      "X :  360\n",
      "INTJ :  2\n",
      "PROPN :  24\n",
      "PART :  2\n"
     ]
    }
   ],
   "source": [
    "comment_text = df[\"comment_text\"].values\n",
    "mistakes = [l for l in comment_text if not l.isupper()]\n",
    "middle = [l.split()[padding_left] for l in comment_text]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(middle)\n",
    "for key, value in counter.items():\n",
    "    print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>session, der blev afbrudt fredag den 17. decem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mellemtiden ønsker jeg - som også en del kolle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907742</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; Sidstnævnt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907743</th>\n",
       "      <td>nøje og om nødvendigt pålægge sanktioner for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907744</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907745</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907746</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1907747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  label\n",
       "0        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "1        session, der blev afbrudt fredag den 17. decem...      1\n",
       "2        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "3        mellemtiden ønsker jeg - som også en del kolle...      1\n",
       "4        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "...                                                    ...    ...\n",
       "1907742  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> Sidstnævnt...      0\n",
       "1907743  nøje og om nødvendigt pålægge sanktioner for a...      1\n",
       "1907744  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "1907745  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "1907746  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "\n",
       "[1907747 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"../Datasets/EuroparlNutidsr_trainset.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "\n",
    "df2 = pd.DataFrame(zip(testset_words, labels), columns=[\"comment_text\", \"label\"])\n",
    "df2.to_csv(\"../Datasets/EuroparlNutidsrWords_trainset.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUNCT PRON AUX VERB NOUN DET ADJ NOUN ADP PUNC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN VERB PRON PUNCT ADP ADV DET NOUN NOUN AUX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907742</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; ADJ AUX VE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907743</th>\n",
       "      <td>ADV CCONJ ADP ADJ VERB NOUN ADP PART VERB SCON...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907744</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907745</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907746</th>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1907747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  label\n",
       "0        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "1        PUNCT PRON AUX VERB NOUN DET ADJ NOUN ADP PUNC...      1\n",
       "2        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "3        NOUN VERB PRON PUNCT ADP ADV DET NOUN NOUN AUX...      0\n",
       "4        <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "...                                                    ...    ...\n",
       "1907742  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> ADJ AUX VE...      1\n",
       "1907743  ADV CCONJ ADP ADJ VERB NOUN ADP PART VERB SCON...      0\n",
       "1907744  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      0\n",
       "1907745  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "1907746  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...      1\n",
       "\n",
       "[1907747 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_text_and_labels = [(c, l) for c, l in zip(comment_text, labels) if c.split()[padding_left] == \"VERB\"]\n",
    "verb_text = [c for c, l in verb_text_and_labels]\n",
    "verb_labels = [l for c, l in verb_text_and_labels]\n",
    "\n",
    "df = pd.DataFrame(zip(verb_text, verb_labels), columns=[\"comment_text\", \"label\"])\n",
    "df.to_csv(\"../Datasets/EuroparlNutidsr_trainset_verbs.csv\", encoding=\"UTF-8\", index=False, sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1091362\n",
       "0     816385\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Number of <PAD> occurrences |   Number of sentences |\n",
      "|-------------------------------|-----------------------|\n",
      "|                             0 |                554467 |\n",
      "|                             1 |                 93141 |\n",
      "|                             2 |                106083 |\n",
      "|                             3 |                109864 |\n",
      "|                             4 |                110262 |\n",
      "|                             5 |                 69577 |\n",
      "|                             6 |                 73365 |\n",
      "|                             7 |                 76837 |\n",
      "|                             8 |                 79791 |\n",
      "|                             9 |                 83933 |\n",
      "|                            10 |                 82827 |\n",
      "|                            11 |                 80119 |\n",
      "|                            12 |                106598 |\n",
      "|                            13 |                 93124 |\n",
      "|                            14 |                163961 |\n",
      "|                            15 |                 11327 |\n",
      "|                            16 |                  7401 |\n",
      "|                            17 |                  3783 |\n",
      "|                            18 |                  1286 |\n",
      "|                            19 |                     1 |\n"
     ]
    }
   ],
   "source": [
    "counts = {i: 0 for i in range(20)}\n",
    "for sentence in verb_text:\n",
    "    num_pads = sentence.count(\"<PAD>\")\n",
    "    counts[num_pads] += 1\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "table = [[\"Number of <PAD> occurrences\", \"Number of sentences\"]]\n",
    "for i in range(20):\n",
    "    table.append([i, counts[i]])\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 323/33276 [00:04<08:18, 66.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m tqdm(duplicates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[0;32m----> 6\u001b[0m     temp \u001b[38;5;241m=\u001b[39m duplicates[\u001b[43mduplicates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m {\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m}:\n\u001b[1;32m      8\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(comment)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "duplicates = df[df.duplicated([\"comment_text\"], keep=False)]\n",
    "result = []\n",
    "for comment in tqdm(duplicates[\"comment_text\"].unique()):\n",
    "    temp = duplicates[duplicates[\"comment_text\"] == comment]\n",
    "    if set(temp[\"label\"]) == {0,1}:\n",
    "        result.append(comment)\n",
    "\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_guess_df = pd.DataFrame(result, columns=[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Datasets/no_guess_df.csv\", encoding=\"UTF-8\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reviewing nutids-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "os.chdir(\"/Users/lucasvilsen/Desktop/GrammatikTAK/Datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"nutids_r.csv\", encoding=\"UTF-8\", sep=\",\", header=None, names=[\"wrong\", \"correct\"])\n",
    "df2 = pd.read_csv(\"EuroparlNutidsr_testset.csv\", encoding=\"UTF-8\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrong</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rigtig mange glæde sig til at ser og inviterer...</td>\n",
       "      <td>rigtig mange glæder sig til at se og invitere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>det er ikke altid nemt at forsvarer din opførsel</td>\n",
       "      <td>det er ikke altid nemt at forsvare din opførsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mange drenge interessere sig for fodbold</td>\n",
       "      <td>mange drenge interesserer sig for fodbold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vil du inviterer alle dine veninder til fødsel...</td>\n",
       "      <td>vil du invitere alle dine veninder til fødsel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>det er svært at vurderer hvor meget bilen er værd</td>\n",
       "      <td>det er svært at vurdere hvor meget bilen er værd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Jeg foreslå, at vi stemme om PSE-gruppens anmo...</td>\n",
       "      <td>Jeg foreslår, at vi stemmer om PSE-gruppens an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>(Forslaget forkastedes) Formanden.</td>\n",
       "      <td>(Forslaget forkastedes) Formanden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Stadig med hensyn til dagsordenen for onsdag h...</td>\n",
       "      <td>Stadig med hensyn til dagsordenen for onsdag h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>PPE-DE-gruppen ønske, at dette punkt tages af ...</td>\n",
       "      <td>PPE-DE-gruppen ønsker, at dette punkt tages af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Ønsker nogen at tager ordet på vegne af gruppe...</td>\n",
       "      <td>Ønsker nogen at tage ordet på vegne af gruppen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 wrong  \\\n",
       "0    rigtig mange glæde sig til at ser og inviterer...   \n",
       "1     det er ikke altid nemt at forsvarer din opførsel   \n",
       "2             mange drenge interessere sig for fodbold   \n",
       "3    vil du inviterer alle dine veninder til fødsel...   \n",
       "4    det er svært at vurderer hvor meget bilen er værd   \n",
       "..                                                 ...   \n",
       "212  Jeg foreslå, at vi stemme om PSE-gruppens anmo...   \n",
       "213                 (Forslaget forkastedes) Formanden.   \n",
       "214  Stadig med hensyn til dagsordenen for onsdag h...   \n",
       "215  PPE-DE-gruppen ønske, at dette punkt tages af ...   \n",
       "216  Ønsker nogen at tager ordet på vegne af gruppe...   \n",
       "\n",
       "                                               correct  \n",
       "0     rigtig mange glæder sig til at se og invitere...  \n",
       "1      det er ikke altid nemt at forsvare din opførsel  \n",
       "2            mange drenge interesserer sig for fodbold  \n",
       "3     vil du invitere alle dine veninder til fødsel...  \n",
       "4     det er svært at vurdere hvor meget bilen er værd  \n",
       "..                                                 ...  \n",
       "212  Jeg foreslår, at vi stemmer om PSE-gruppens an...  \n",
       "213                 (Forslaget forkastedes) Formanden.  \n",
       "214  Stadig med hensyn til dagsordenen for onsdag h...  \n",
       "215  PPE-DE-gruppen ønsker, at dette punkt tages af...  \n",
       "216  Ønsker nogen at tage ordet på vegne af gruppen...  \n",
       "\n",
       "[217 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
